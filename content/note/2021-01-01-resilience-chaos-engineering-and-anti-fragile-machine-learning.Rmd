---
title: Resilience, Chaos Engineering and Anti-Fragile Machine Learning
author: Tim Radtke
date: '2021-01-01'
slug: resilience-chaos-engineering-and-anti-fragile-machine-learning
categories: []
tags: []
---

In his [interview with The Observer Effect](https://www.theobservereffect.org/tobi.html), Tobi Lütke, CEO of Shopify, describes how Shopify benefits from resilient systems:

> Most interesting things come from non-deterministic behaviors. People have a love for the predictable, but there is value in being able to build systems that can absorb whatever is being thrown at them and still have good outcomes.

> So, I love Antifragile, and I make everyone read it. It finally put a name to an important concept that we practiced. Before this, I would just log in and shut down various servers to teach the team what’s now called chaos engineering.

> But we've done this for a long, long time. We've designed Shopify very well because resilience and uptime are so important for building trust. These lessons were there in the building of our architecture. And then I had to take over as CEO.

It sticks out that Lütke uses “resilient” and “antifragile” interchangeably even though Taleb would point out that they are not the same thing: Whereas a resilient system doesn't fail due to randomly turned off servers, an antifragile system benefits. (Are Shopify's systems robust or have they become somehow better beyond robust due to their exposure to "chaos"?)

But this doesn’t diminish Lütke's notion of resilience and uptime being "so important for building trust" (with users, presumably): Users' trust in applications is fragile. Earning users’ trust in a tool that augments or automates decisions is difficult, and the trust is withdrawn quickly when the tool makes a stupid mistake. Making your tool robust against failure modes is how you make it trustworthy---and used.

Which makes it interesting to reason about what an equivalent to shutting off random servers is to machine learning applications (beyond shutting off the server running the model). Label noise? Shuffling features? Adding Covid-19-style disruptions to your time series? The latter might be more related to the idea of [experimenting with a software system in production](https://en.wikipedia.org/wiki/Chaos_engineering). 

And—to return to the topic of discerning anti-fragile and robust—what would it mean for machine learning algorithms “to gain from disorder”? [Dropout](https://jmlr.org/papers/v15/srivastava14a.html) comes to mind. What about causal inference through [natural experiments](https://en.wikipedia.org/wiki/Natural_experiment)?